{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv4-tiny-Darknet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nclarknz/DarkNet-Obj-Training/blob/main/YOLOv4_tiny_Darknet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNVU7eu9CQj3"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "In this notebook, we implement the tiny version of [YOLOv4](https://arxiv.org/pdf/2004.10934.pdf) for training on your own dataset, [YOLOv4 tiny](https://github.com/AlexeyAB/darknet/issues/6067). This is where darknet came from\n",
        "\n",
        "Also recommend reading the roboflow blog post on [Training YOLOv4 on custom data](https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/) side by side. This is where I got the original file from, but then modified to suit my requirements\n",
        "\n",
        "We will take the following steps to implement YOLOv4 on our custom data:\n",
        "* Configure our GPU environment on Google Colab\n",
        "* Install the Darknet YOLOv4 training environment\n",
        "* Download our custom dataset for YOLOv4 and set up directories\n",
        "      Training data iages and yolo files should be in darknet/data/obj \n",
        "      Valid data images and yolo file should be in darknet/data/objvalid\n",
        "      \n",
        "      change darknet/data/obj.data to suit setup and filenames\n",
        "      darknet/data/obj.names shoul dbe list of classes / labelnames \n",
        "\n",
        "* Configure a custom YOLOv4 training config file for Darknet\n",
        "* Train our custom YOLOv4 object detector\n",
        "* Reload YOLOv4 trained weights and make inference on test images\n",
        "\n",
        "When you are done you will have a custom detector that you can use. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDTvGt2zt7cm"
      },
      "source": [
        "# Configuring cuDNN on Colab for YOLOv4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyY-kHHzbyUP"
      },
      "source": [
        "# Setup the Google Drive and stuff\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd /content/gdrive/My Drive/KiwiBoxSet\n",
        "%cd /content\n",
        "!ln -s  '/content/gdrive/My Drive/KiwiBoxSet' kiwiboxset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-bguKWgtxSx"
      },
      "source": [
        "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it.\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "# We need to install the correct cuDNN according to this output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6BRAVo182G5"
      },
      "source": [
        "#take a look at the kind of GPU we have\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16pvdFMa1FEe"
      },
      "source": [
        "# Installing Darknet for YOLOv4 on Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9uY-38P93oz",
        "outputId": "ebf70ba9-000a-4431-9c1c-0cef7c6d53d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/kiwiboxset\n",
        "#%rm -rf darknet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/KiwiBoxSet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQEktcfj9y9O"
      },
      "source": [
        "#we clone the fork of darknet maintained by roboflow\n",
        "#small changes have been made to configure darknet for training\n",
        "!git clone https://github.com/roboflow-ai/darknet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FS9Fd4-Yi8-"
      },
      "source": [
        "**IMPORTANT! If you're not using a Tesla P100 GPU, then uncomment the sed command and replace the arch and code with that matching your GPU. A list can be found [here](http://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyMBDkaL-Aep"
      },
      "source": [
        "#install environment from the Makefile\n",
        "%cd /content/kiwiboxset/darknet/\n",
        "# compute_30, sm_30 for Tesla K80\n",
        "# compute_75, sm_75 for Tesla T4\n",
        "!sed -i 's/ARCH= -gencode arch=compute_60,code=sm_60/ARCH= -gencode arch=compute_75,code=sm_75/g' Makefile\n",
        "#!sed -i 's/ARCH= -gencode arch=compute_75,code=sm_75/ARCH= -gencode arch=compute_30,code=sm_30/g' Makefile\n",
        "#install environment from the Makefile\n",
        "#note if you are on Colab Pro this works on a P100 GPU\n",
        "#if you are on Colab free, you may need to change the Makefile for the K80 GPU\n",
        "#this goes for any GPU, you need to change the Makefile to inform darknet which GPU you are running on.\n",
        "!make clean\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVClStFPItyL"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkXPrquAGt-_"
      },
      "source": [
        "Next Stage will download the tiny weights file for Yolo v4. Use this to start the training. Then can us ethe last weights file in teh bacup folder to continue training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGPDEjfAALrQ"
      },
      "source": [
        "#download the newly released yolov4-tiny weights\n",
        "%cd /content/kiwiboxset/darknet\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29\n",
        "#!wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-tiny.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWOiKj37l4wW"
      },
      "source": [
        "# Set up Custom Dataset for YOLOv4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbniFj-eSimL"
      },
      "source": [
        "Move files around from zipped folder and setup the training and validation files if required. Mainly commented out as do this local before upload of the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiCILEbs1NII",
        "outputId": "c5240185-8cd9-4376-cdfc-953ed01044e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Set up training file directories for custom dataset\n",
        "%cd /content/kiwiboxset/darknet/data/obj/12.zip\\ \\(Unzipped\\ Files\\)/\n",
        "\n",
        "#%cp train/_darknet.labels data/obj.names\n",
        "#%mkdir data/obj\n",
        "#copy image and labels\n",
        "#%cp train/*.jpg data/obj/\n",
        "#%cp valid/*.jpg data/obj/\n",
        "%mv * /content/kiwiboxset/darknet/data/obj\n",
        "#%cp train/*.txt data/obj/\n",
        "#%cp valid/*.txt data/obj/\n",
        "%ls -l /content/kiwiboxset/darknet/data/obj | wc -l\n",
        "%ls -l  | wc -l\n",
        "#with open('data/obj.data', 'w') as out:\n",
        "#  out.write('classes = 26\\n')\n",
        "#  out.write('train = data/train.txt\\n')\n",
        "#  out.write('valid = data/valid.txt\\n')\n",
        "#  out.write('names = data/obj.names\\n')\n",
        "#  out.write('backup = backup/')\n",
        "\n",
        "#write train file (just the image list)\n",
        "import os\n",
        "\n",
        "#with open('data/train.txt', 'w') as out:\n",
        "#  for img in [f for f in os.listdir('train') if f.endswith('jpg')]:\n",
        "#    out.write('data/obj/' + img + '\\n')\n",
        "\n",
        "#write the valid file (just the image list)\n",
        "#import os\n",
        "\n",
        "#with open('data/valid.txt', 'w') as out:\n",
        "#  for img in [f for f in os.listdir('valid') if f.endswith('jpg')]:\n",
        "#    out.write('data/obj/' + img + '\\n')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/KiwiBoxSet/darknet/data/obj/12.zip (Unzipped Files)\n",
            "3548\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HtRqO3QvjkP"
      },
      "source": [
        "# Write Custom Training Config for YOLOv4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_WJcqHhpeVr",
        "outputId": "5dfc2657-d82d-439b-f23a-54d7e12026e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#we build config dynamically based on number of classes\n",
        "#we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\n",
        "def file_len(fname):\n",
        "  with open(fname) as f:\n",
        "    for i, l in enumerate(f):\n",
        "      pass\n",
        "  return i + 1\n",
        "\n",
        "num_classes = file_len('data/obj.names')\n",
        "max_batches = num_classes*5000\n",
        "steps1 = .8 * max_batches\n",
        "steps2 = .9 * max_batches\n",
        "steps_str = str(steps1)+','+str(steps2)\n",
        "num_filters = (num_classes + 5) * 3\n",
        "\n",
        "\n",
        "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
        "\n",
        "#Instructions from the darknet repo\n",
        "#change line max_batches to (classes*2000 but not less than number of training images, and not less than 6000), f.e. max_batches=6000 if you train for 3 classes\n",
        "#change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
        "if os.path.exists('./cfg/custom-yolov4-tiny-detector.cfg'): os.remove('./cfg/custom-yolov4-tiny-detector.cfg')\n",
        "\n",
        "\n",
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "writing config for a custom YOLOv4 detector detecting number of classes: 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03VuD4NHnxFx"
      },
      "source": [
        "%%writetemplate ./cfg/custom-yolov4-tiny-detector.cfg\n",
        "[net]\n",
        "# Testing\n",
        "#batch=1\n",
        "#subdivisions=1\n",
        "# Training\n",
        "batch=64\n",
        "subdivisions=24\n",
        "width=416\n",
        "height=416\n",
        "channels=3\n",
        "momentum=0.9\n",
        "decay=0.0005\n",
        "angle=0\n",
        "saturation = 1.5\n",
        "exposure = 1.5\n",
        "hue=.1\n",
        "\n",
        "learning_rate=0.00261\n",
        "burn_in=1000\n",
        "max_batches = {max_batches}\n",
        "policy=steps\n",
        "steps={steps_str}\n",
        "scales=.1,.1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers=-1\n",
        "groups=2\n",
        "group_id=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1,-2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -6,-1\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers=-1\n",
        "groups=2\n",
        "group_id=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1,-2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -6,-1\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers=-1\n",
        "groups=2\n",
        "group_id=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1,-2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -6,-1\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "##################################\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "\n",
        "\n",
        "[yolo]\n",
        "mask = 3,4,5\n",
        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
        "classes={num_classes}\n",
        "num=6\n",
        "jitter=.3\n",
        "scale_x_y = 1.05\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=0\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "[route]\n",
        "layers = -4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = -1, 23\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[yolo]\n",
        "mask = 1,2,3\n",
        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
        "classes={num_classes}\n",
        "num=6\n",
        "jitter=.3\n",
        "scale_x_y = 1.05\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=0\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "max=200"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2LAciMh4Cut",
        "outputId": "3e16b3b5-3063-43ed-e193-6d061612c2a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#here is the file that was just written. \n",
        "#you may consider adjusting certain things\n",
        "\n",
        "#like the number of subdivisions 64 runs faster but Colab GPU may not be big enough\n",
        "#if Colab GPU memory is too small, you will need to adjust subdivisions to 16\n",
        "%cat cfg/custom-yolov4-tiny-detector.cfg"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[net]\n",
            "# Testing\n",
            "#batch=1\n",
            "#subdivisions=1\n",
            "# Training\n",
            "batch=64\n",
            "subdivisions=24\n",
            "width=416\n",
            "height=416\n",
            "channels=3\n",
            "momentum=0.9\n",
            "decay=0.0005\n",
            "angle=0\n",
            "saturation = 1.5\n",
            "exposure = 1.5\n",
            "hue=.1\n",
            "\n",
            "learning_rate=0.00261\n",
            "burn_in=1000\n",
            "max_batches = 130000\n",
            "policy=steps\n",
            "steps=104000.0,117000.0\n",
            "scales=.1,.1\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=32\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers=-1\n",
            "groups=2\n",
            "group_id=1\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=32\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=32\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -1,-2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -6,-1\n",
            "\n",
            "[maxpool]\n",
            "size=2\n",
            "stride=2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers=-1\n",
            "groups=2\n",
            "group_id=1\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -1,-2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -6,-1\n",
            "\n",
            "[maxpool]\n",
            "size=2\n",
            "stride=2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers=-1\n",
            "groups=2\n",
            "group_id=1\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -1,-2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -6,-1\n",
            "\n",
            "[maxpool]\n",
            "size=2\n",
            "stride=2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "##################################\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=93\n",
            "activation=linear\n",
            "\n",
            "\n",
            "\n",
            "[yolo]\n",
            "mask = 3,4,5\n",
            "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
            "classes=26\n",
            "num=6\n",
            "jitter=.3\n",
            "scale_x_y = 1.05\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=0\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "\n",
            "[route]\n",
            "layers = -4\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = -1, 23\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=93\n",
            "activation=linear\n",
            "\n",
            "[yolo]\n",
            "mask = 1,2,3\n",
            "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
            "classes=26\n",
            "num=6\n",
            "jitter=.3\n",
            "scale_x_y = 1.05\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=0\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "max=200"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWrG9EGamSpH"
      },
      "source": [
        "# Train Custom YOLOv4 Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6miYFbvExqMd"
      },
      "source": [
        "%cd /content/kiwiboxset/darknet/\n",
        "!./darknet detector train data/obj.data cfg/custom-yolov4-tiny-detector.cfg yolov4-tiny.conv.29 -dont_show -map\n",
        "#!./darknet detector train data/obj.data cfg/custom-yolov4-tiny-detector.cfg backup/custom-yolov4-tiny-detector_last.weights -dont_show -map\n",
        "#If you get CUDA out of memory adjust subdivisions above!\n",
        "#adjust max batches down for shorter training above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBnwpBV5ZXxQ"
      },
      "source": [
        "# Infer Custom Objects with Saved YOLOv4 Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vHTsL-TE1EL"
      },
      "source": [
        "%cd /content/kiwiboxset/darknet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzoJQQw8Zdco"
      },
      "source": [
        "import os\n",
        "#define utility function\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  #plt.rcParams['figure.figsize'] = [10, 5]\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3dJB6NZv4kh"
      },
      "source": [
        "#check if weigths have saved yet\n",
        "#backup houses the last weights for our detector\n",
        "#(file yolo-obj_last.weights will be saved to the build\\darknet\\x64\\backup\\ for each 100 iterations)\n",
        "#(file yolo-obj_xxxx.weights will be saved to the build\\darknet\\x64\\backup\\ for each 1000 iterations)\n",
        "#After training is complete - get result yolo-obj_final.weights from path build\\darknet\\x64\\bac\n",
        "!ls -l backup\n",
        "#if it is empty you haven't trained for long enough yet, you need to train for at least 100 iterations\n",
        "#!chmod 775 darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-_E3O5Mf4Mf"
      },
      "source": [
        "#coco.names is hardcoded somewhere in the detector\n",
        "%cp data/obj.names data/coco.names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjKzw2TvZrOQ"
      },
      "source": [
        "\n",
        "#/test has images that we can test our detector on\n",
        "test_images = [f for f in os.listdir('test') if f.endswith('.jpg')]\n",
        "#import random\n",
        "#img_path = \"test/\" + random.choice(test_images);\n",
        "for img in test_images: \n",
        "#test out our detector!\n",
        "    !./darknet detect cfg/custom-yolov4-tiny-detector.cfg backup/custom-yolov4-tiny-detector_best.weights test/{img} -dont-show\n",
        "    #imShow('predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhNDuO_BtgHO"
      },
      "source": [
        "#Now Convert to TF Lite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSCKx3i7aWr9"
      },
      "source": [
        "%cd /content/kiwiboxset/\n",
        "!git clone https://github.com/hunglc007/tensorflow-yolov4-tflite.git\n",
        "%cd /content/kiwiboxset/tensorflow-yolov4-tflite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPamGzluuCeN"
      },
      "source": [
        "Then, we'll change the labels from the default COCO to our own custom ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE-kX_jht0Ul",
        "outputId": "21bf1dde-fd6e-4d13-b8fa-6b76d0794d48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!cp /content/kiwiboxset/darknet/data/obj.names /content/kiwiboxset/tensorflow-yolov4-tflite/data/classes/\n",
        "!ls /content/kiwiboxset/tensorflow-yolov4-tflite/data/classes/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "coco.names  obj.names  voc.names  yymnist.names\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YJsvfP5t8tZ"
      },
      "source": [
        "!sed -i \"s/coco.names/obj.names/g\" /content/kiwiboxset/tensorflow-yolov4-tflite/core/config.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCYLOOwEuFdj"
      },
      "source": [
        "##Convert to TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjPgJl4OuQIO"
      },
      "source": [
        "Time to convert! We'll convert to both a regular TensorFlow SavedModel and to TensorFlow Lite. For TensorFlow Lite, we'll convert to a different TensorFlow SavedModel beforehand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK7ShOCZuEQk"
      },
      "source": [
        "%cd /content/kiwiboxset/tensorflow-yolov4-tflite\n",
        "# Regular TensorFlow SavedModel\n",
        "!python save_model.py \\\n",
        "  --weights /content/kiwiboxset/darknet/backup/custom-yolov4-tiny-detector_best.weights \\\n",
        "  --output ./checkpoints/yolov4-tiny-512512v2 \\\n",
        "  --input_size 512 \\\n",
        "  --model yolov4 \\\n",
        "  --tiny \\\n",
        "\n",
        "# SavedModel to convert to TFLite\n",
        "!python save_model.py \\\n",
        "  --weights /content/kiwiboxset/darknet/backup/custom-yolov4-tiny-detector_best.weights \\\n",
        "  --output ./checkpoints/yolov4-tiny-pretflite-512512v2 \\\n",
        "  --input_size 512 \\\n",
        "  --model yolov4 \\\n",
        "  --tiny \\\n",
        "  --framework tflite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnGC8UExueEn"
      },
      "source": [
        "# Convert the TensorFlow weights to TensorFlow Lite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9D38FH7ukPN"
      },
      "source": [
        "%cd /content/kiwiboxset/tensorflow-yolov4-tflite\n",
        "!python convert_tflite.py --weights ./checkpoints/yolov4-tiny-pretflite-512512v2 --output ./checkpoints/yolov4-tiny-512v2.tflite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWzXx9BUutGT"
      },
      "source": [
        "!ls /content/kiwiboxset/darknet/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt15y_oyuy4L"
      },
      "source": [
        "# Verify\n",
        "%cd /content/kiwiboxset/tensorflow-yolov4-tflite\n",
        "!python detect.py --weights ./checkpoints/yolov4-tiny-1024768v5 --size 1024x768 --model yolov4 \\\n",
        "  --image /content/kiwiboxset/darknet/test/imgma.JPG \\\n",
        "  # --framework tflite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wowfBKO3vAhr"
      },
      "source": [
        "%cd /content/kiwiboxset/tensorflow-yolov4-tflite/\n",
        "!ls\n",
        "from IPython.display import Image\n",
        "Image('/content/kiwiboxset/tensorflow-yolov4-tflite/result.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A6VeIknD37j"
      },
      "source": [
        "# Eval Model\n",
        "\n",
        "Not sure if fully working"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0ZxA7XED2uI"
      },
      "source": [
        "# evaluate yolov4 model\n",
        "%cd /content/kiwiboxset/tensorflow-yolov4-tflite/\n",
        "!python evaluate.py --weights /content/kiwiboxset/tensorflow-yolov4-tflite/checkpoints/yolov4-tiny-1024768v5/  --tiny True  --size 1024x768 --model yolov4\n",
        "#%cd mAP/extra\n",
        "#python remove_space.py\n",
        "#%cd ..\n",
        "#python main.py --output results_yolov4_tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdTO8el1Jvs9"
      },
      "source": [
        "%cd /content/kiwiboxset/tensorflow-yolov4-tflite/mAP\n",
        "#%cd mAP/extra\n",
        "#!python remove_space.py\n",
        "#%cd ..\n",
        "!python main.py --output results_yolov4_tf"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}